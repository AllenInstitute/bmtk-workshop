{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6B. Generating Input\n",
    "\n",
    "[**Return to the main chapter contents**](6.%20More%20Realistic%20Model%20and%20Advanced%20Features.ipynb)\n",
    "\n",
    "In Section 6A we used BMTK's ```NetworkBuilder``` to build a reduced model of the mouse visual cortex which was saved in the **network/** directory. In the rest of the chapter we will use the ```PointNet``` simulator to run multiple simulations of the network. First, we will want to generate spike train data to drive the simulation.\n",
    "\n",
    "Generating input spike-trains for the model can require a fair amount of time and computation (expect ~10-30 minutes to generate visual stimulus inputs for LGN). As such we have already saved input spike trains into the **inputs/** directory. However should one need to re-generate inputs (in the case the LGN node coordinates have been updated) or if you want to create additional input, please proceed, but note that it will overwrite the existing generated inputs.\n",
    "\n",
    "Here we will be using ```FilterNet```, the basics of which were already covered in a [previous chapter](../Ch5_filternet/5.%20FilterNet.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import h5py\n",
    "\n",
    "from bmtk.utils import sonata\n",
    "from bmtk.utils.reports.spike_trains import PoissonSpikeGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LGN Inputs\n",
    "\n",
    "The main driver of the system is the \"lgn\" network we created in the previous section. The \"lgn\" nodes consist of cells that operate as filters in the visual space, with properties that mimic types of cells found in the mammalian visual thalamus. Using ```FilterNet``` we can run a variety of visual stimuli through the lgn filters to generate realistic responses. Then we can use those responses to drive the main visual cortex network.\n",
    "\n",
    "First let us use bmtk.utils.sonata to determine the make-up and distribution of our LGN model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = sonata.File(\n",
    "    data_files='network/lgn_nodes.h5',\n",
    "    data_type_files='network/lgn_node_types.csv'\n",
    ")\n",
    "lgn_nodes_df = net.nodes['lgn'].to_dataframe(index_by_id=False)\n",
    "lgn_nodes_df['node_count'] = 1\n",
    "lgn_nodes_df[['model_name', 'model_template', 'node_count']].groupby(['model_name', 'model_template']).agg('count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_grids = 15\n",
    "y_grids = 10\n",
    "size = (240.0, 120.0)\n",
    "fig, ax = plt.subplots(1, 1, figsize=(16, 8))\n",
    "\n",
    "for model_name, model_df in lgn_nodes_df.groupby('model_name'):\n",
    "    ax.scatter(model_df['x'].values, model_df['y'].values, s=10, label=model_name)\n",
    "\n",
    "ax.set_xticks(np.arange(0, size[0]+x_grids, size[0]/x_grids))\n",
    "ax.set_yticks(np.arange(0, size[1]+y_grids, size[1]/y_grids))\n",
    "ax.legend()\n",
    "ax.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FilterNet Config\n",
    "\n",
    "We will start with a moving grating running at a 90 degree angle at a rate of 4 Hz, with a 500 ms grey-screen at the start. Update the ```config.simulation_filternet.dg_90deg_4Hz.json``` in the inputs sections:\n",
    "\n",
    "```json\n",
    "  \"inputs\": {\n",
    "    \"gratings\": {\n",
    "      \"input_type\": \"movie\",\n",
    "      \"module\": \"graiting\",\n",
    "      \"row_size\": 120,\n",
    "      \"col_size\": 240,\n",
    "      \"gray_screen_dur\": 500.0,\n",
    "      \"cpd\": 0.04,\n",
    "      \"temporal_f\": 4.0,\n",
    "      \"contrast\": 0.8,\n",
    "      \"theta\": 90.0,\n",
    "      \"evaluation_options\": {\n",
    "        \"downsample\": 1,\n",
    "        \"separable\": true\n",
    "      }\n",
    "    }\n",
    "  },\n",
    "```\n",
    "\n",
    "To make things easier, instead of saving the results into the **output/** directory, it will be saved into the **inputs/** directory. This is because we want to use these results as the inputs into our ```PointNet``` visual cortex model. \n",
    "\n",
    "Note that we are actually saving a couple of files; the *rates* file contains the raw firing rate traces for each individual LGN cell in hdf5 format. ```FilterNet``` uses these rates and a Poisson process to convert the time-dependent firing rates into spike trains and saves it in the *spikes_file* in SONATA format.\n",
    "\n",
    "```json\n",
    "   \"output\":{\n",
    "     \"log_file\": \"log.txt\",\n",
    "     \"output_dir\": \"./inputs\",\n",
    "     \"rates_h5\": \"rates.gratings.dg_90deg_4Hz.h5\",\n",
    "     \"spikes_file\": \"spikes.gratings.dg_90deg_4Hz.h5\",\n",
    "     \"spikes_file_csv\": \"spikes.gratings.dg_90deg_4Hz.csv\"\n",
    "   },\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Running FilterNet simulation\n",
    "\n",
    "We can generate gratings input to our lgn cells either through the command line, with access to MPI:\n",
    "\n",
    "```bash\n",
    " $ mpirun -np <N> python run_filternet.py config.simulation_filternet.dg_90deg_4Hz.json\n",
    "```\n",
    "\n",
    "or, with some modifications to the script we can run it in the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bmtk.simulator import filternet\n",
    "\n",
    "configs = [\n",
    "    # drifting gratings at 2 Hz\n",
    "    'config.simulation_filternet.dg_0deg_2Hz.json',\n",
    "    'config.simulation_filternet.dg_45deg_2Hz.json',\n",
    "    'config.simulation_filternet.dg_90deg_2Hz.json',   \n",
    "    # drifting gratings at 4 Hz\n",
    "    'config.simulation_filternet.dg_0deg_4Hz.json',\n",
    "    'config.simulation_filternet.dg_45deg_4Hz.json',\n",
    "    'config.simulation_filternet.dg_90deg_4Hz.json',\n",
    "    # Full Field flashes\n",
    "    # 'config.simulation_filternet.flash_on.json',\n",
    "    # 'config.simulation_filternet.flash_off.json'\n",
    "]\n",
    "\n",
    "\n",
    "for config_file in configs:\n",
    "    print('Running {}'.format(config_file))\n",
    "    config = filternet.Config.from_json(config_file)\n",
    "    config.build_env()\n",
    "\n",
    "    net = filternet.FilterNetwork.from_config(config)\n",
    "    sim = filternet.FilterSimulator.from_config(config, net)\n",
    "    sim.run()\n",
    "    print(' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Besides the spikes we generated, ```FilterNet``` also saved the raw firing rates such that we can see the simulated lgn responses to the stimulus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_firing_rates(rates_file):\n",
    "    net = sonata.File(\n",
    "        data_files='network/lgn_nodes.h5',\n",
    "        data_type_files='network/lgn_node_types.csv'\n",
    "    )\n",
    "    lgn_nodes_df = net.nodes['lgn'].to_dataframe(index_by_id=False)\n",
    "    lgn_nodes_df = lgn_nodes_df[['node_id', 'model_name']]\n",
    "\n",
    "    fig, axes = plt.subplots(1, 1, figsize=(16, 8))\n",
    "    with h5py.File(rates_file, 'r') as h5:\n",
    "        node_ids_lu = h5['/firing_rates/lgn/node_id'][()]\n",
    "        firing_rates_hz = h5['/firing_rates/lgn/firing_rates_Hz']\n",
    "\n",
    "        for model_name, model_df in lgn_nodes_df.groupby('model_name'):\n",
    "            node_ids = model_df['node_id'].values\n",
    "            node_ids_idx = node_ids_lu[node_ids]\n",
    "            model_frs = firing_rates_hz[:, node_ids_idx]\n",
    "            model_frs_avg = np.mean(model_frs, axis=1)\n",
    "            axes.plot(model_frs_avg, label=model_name)\n",
    "\n",
    "    axes.set_xlabel('Time (ms)')\n",
    "    axes.set_ylabel('Firing Rates (Hz)')\n",
    "    axes.legend(fontsize='small')\n",
    "    plt.show()\n",
    "    \n",
    "plot_firing_rates('inputs/rates.gratings.90deg_4Hz.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BKG Inputs\n",
    "\n",
    "For the non-thalamocortical background we will use a simple Poisson Process with a constant firing rate of 1 kHz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psg = PoissonSpikeGenerator()\n",
    "psg.add(node_ids='network/bkg_nodes.h5', firing_rate=1000.0, times=(0.0, 3.0), population='bkg')\n",
    "psg.to_sonata('inputs/bkg_spikes.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[**Return to the main chapter contents**](6.%20More%20Realistic%20Model%20and%20Advanced%20Features.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bmtk-py3.11",
   "language": "python",
   "name": "bmtk-py3.11"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
