{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Multicell population\n",
    "\n",
    "In the last chapter we showed how to build, set up and run a full simulation from scratch of a network consisting of only one cell. This time we will build and simulate a network of many cells across multiple cell types. As we will see the procedure is much the same for building a heterogeneous network of many cells as it is for a single cell network. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import h5py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from bmtk.builder.networks import NetworkBuilder\n",
    "from bmtk.builder.bionet import rand_syn_locations\n",
    "from bmtk.utils.reports.spike_trains import PoissonSpikeGenerator\n",
    "from bmtk.utils.create_environment import create_environment\n",
    "from bmtk.analyzer.spike_trains import plot_raster\n",
    "from bmtk.analyzer.compartment import plot_traces\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Tip</b>: When running the notebook for the first time it is recommended to clear out the existing network directory. Similarly if running the notebook multiple times the results of the previous build may affect the notebook if the SONATA files are not cleared out.\n",
    "</div>\n",
    "\n",
    "We can delete any existing SONATA network files either through the command line:\n",
    "```bash\n",
    "  $ rm -r network/\n",
    "```\n",
    "or with the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in glob.glob('network/*'):\n",
    "    try:\n",
    "        os.remove(f)\n",
    "    except FileNotFoundError as fnfe:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Tip</b>: There is a small amount of biologically relevant randomness built into the models and simulation, so every time the notebook is run it is expected to get different results. However, should you want to match the same results with the \"completed\" version of the tutorials please use the rng seed below:\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Network Model\n",
    "\n",
    "The first step is to determine what \"Cell Types\" models we want to use in our network, both in terms of the population make-up of the network, and if we are going to create new model files/parameters or incorporate existing ones. In SONATA and BioNet we have the option of incorporating NEURON hoc code and templates, as well as NeuroML files. Thus we can download our cell models from places like ModelDB or The Blue Brain Project. But for this tutorial we will stick to the [Allen Cell-Types Database](https://celltypes.brain-map.org/data).\n",
    "\n",
    "We will want to use the Allen Cell-Types Feature Seach to select a certain number of cell types as we did in the [last tutorial](../Ch2_single_cell/2.%20Single%20Cell.ipynb#Choosing-your-cell-models). We've already selected and downloaded them for you and placed them in the _components/_ directory. If you want to choose your own cell models, remember that since we are trying to simulate them as bio-realistic models, check that any models have a morphology (\"Reconstruction Type\": \"Full\") and a Biophysical model (either \"All-activate\" or \"Perisomatic\").\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Building Cells\n",
    "\n",
    "<br>\n",
    "<div>\n",
    "  <img src=\"../images/builder_add_nodes.png\" width=\"500\" align=\"left\" style=\"margin-left:5px\"/>    \n",
    "</div>\n",
    "<br clear=\"left\">\n",
    "\n",
    "\n",
    "For our example we will build a scaled-down model of the mouse L4 primary visual cortex. For simplicity, we will use three excitatory cell types and one inhibitory type found in the mouse L4 of the Allen Cell-Types Database. To make the simulation efficient enough to run on a single processor in a reasonable amount of time we will model only 75 biophysically-detailed cells. To keep the ratio of excitatory-to-inhibitory cells realistic we will want have 80% excitatory cells and 20% inhibitory cells. To place the cells in space, we will generate a cylinder of random coordinates (with _y_ being the vertical axis traversing the cortical layers and orthogonal to the pia mater)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def get_coords(N, radius_min=0.0, radius_max=400.0):\n",
    "    phi = 2.0 * np.pi * np.random.random([N])\n",
    "    r = np.sqrt((radius_min**2 - radius_max**2) * np.random.random([N]) + radius_max**2)\n",
    "    x = r * np.cos(phi)\n",
    "    y = np.random.uniform(400.0, 500.0, size=N)\n",
    "    z = r * np.sin(phi)\n",
    "    return x, y, z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We call our network \"l4\" and start off by creating a subpopulation of \"Scnn1a\" type cells using the ```add_nodes()``` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bmtk.builder.networks import NetworkBuilder\n",
    "\n",
    "l4 = NetworkBuilder('l4')\n",
    "\n",
    "x, y, z = get_coords(20)\n",
    "assert(len(x) == len(y) == len(z) == 20)\n",
    "\n",
    "l4.add_nodes(\n",
    "    N=20,\n",
    "    \n",
    "    # Reserved SONATA keywords used during simulation\n",
    "    model_type='biophysical',\n",
    "    model_template='ctdb:Biophys1.hoc',\n",
    "    model_processing='aibs_perisomatic',\n",
    "    dynamics_params='Scnn1a_485510712_params.json',\n",
    "    morphology='Scnn1a_485510712_morphology.swc',\n",
    "    \n",
    "    # The x, y, z locations and orientations (in Euler angles) of each cell\n",
    "    # Here, rotation around the pia-to-white-matter axis is randomized\n",
    "    x=x,\n",
    "    y=y,\n",
    "    z=z,\n",
    "    rotation_angle_xaxis=0,\n",
    "    rotation_angle_yaxis=np.random.uniform(0.0, 2*np.pi, size=20),\n",
    "    rotation_angle_zaxis=np.full(20, 3.73),\n",
    "    \n",
    "    # Optional parameters\n",
    "    tuning_angle=np.linspace(start=0.0, stop=360.0, num=20, endpoint=False),\n",
    "    model_name='Scnn1a',\n",
    "    ei_type='e'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* By setting __N__=20 we are creating 20 individual Scnn1a type cells. \n",
    "\n",
    "* Properties **model_type**, **model_template**, and **model_processing** are directives to indicate to BMTK that we are building Allen-Cell Type Perisomatic model. The next properties, **dynamics_params** and **morphology**, refer to the electrophysiology and morphology files we downloaded from the Allen Cell-Types Databases.\n",
    "\n",
    "* Next we set the coordinates and rotation angles for individual cells. Note that for **x**, **y**, **z**, **rotation_angle_yaxis**, and **rotation_angle_zaxis** we are passing in lists of size **N** so that each coordinate in unique to each cell.\n",
    "\n",
    "* Finally we add optional attributes and metadata germane to our Visual L4 model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### [SIDE-TRACK]: Node-Type vs Node Properties\n",
    "---\n",
    "---\n",
    "In SONATA, every node-type (or cell-type) will contain one or more individual nodes (or cells). Certain properties will have values that are identical and shared by every individual node, while other properties will have unique values for each cell. Whether or not a property is shared or unique will change how they are stored in the format.\n",
    "\n",
    "In the BMTK NetworkBuilder, we can use strings, numbers, boolean and other non-list values to set a value as being \"shared\". It will also recognize Python tuples as being \"shared\" cell-type properties.\n",
    "\n",
    "```python\n",
    "net.add_nodes(\n",
    "    N=100,\n",
    "    prop_A='shared',\n",
    "    prop_B=2.71828,\n",
    "    prop_C=('foo', 'bar')\n",
    "    ...\n",
    "```\n",
    "All 100 individual cells will share the values of **prop_A**, **prop_B**, and **prop_C**.\n",
    "\n",
    "\n",
    "If we want to assign unique values for each indivdiual node we should pass in either a list, array, generator or range value\n",
    "\n",
    "```python\n",
    "net.add_nodes(\n",
    "    N=100,\n",
    "    prop_D=['unique']*100,\n",
    "    prop_B=np.random.uniform(0, 1.0, size=100),\n",
    "    prop_C=range(0, 100)\n",
    "    ...\n",
    "```\n",
    "---\n",
    "---\n",
    "\n",
    "We will continue on building the other nodes in much the same way by making additional calls to ```add_nodes()```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y, z = get_coords(20)\n",
    "l4.add_nodes(\n",
    "    # Rorb excitatory cells\n",
    "    N=20,\n",
    "    model_type='biophysical',\n",
    "    model_template='ctdb:Biophys1.hoc',\n",
    "    dynamics_params='Rorb_486509958_params.json',\n",
    "    morphology='Rorb_486509958_morphology.swc',\n",
    "    model_processing='aibs_perisomatic',\n",
    "    \n",
    "    x=x, y=y, z=z,   \n",
    "    rotation_angle_xaxis=0,\n",
    "    rotation_angle_yaxis=np.random.uniform(0.0, 2*np.pi, size=20),\n",
    "    rotation_angle_zaxis=np.full(20, 4.40),\n",
    "    \n",
    "    model_name='Rorb', \n",
    "    ei_type='e',\n",
    "    tuning_angle=np.linspace(start=0.0, stop=360.0, num=20, endpoint=False),\n",
    ")\n",
    "\n",
    "x, y, z = get_coords(20)\n",
    "l4.add_nodes(\n",
    "    # Nr5a1 excitatory cells\n",
    "    N=20,\n",
    "    model_type='biophysical',\n",
    "    model_template='ctdb:Biophys1.hoc',\n",
    "    dynamics_params='Nr5a1_485507735_params.json',\n",
    "    morphology='Nr5a1_485507735_morphology.swc',\n",
    "    model_processing='aibs_perisomatic',\n",
    "    \n",
    "    x=x, y=y, z=z,    \n",
    "    rotation_angle_xaxis=0,\n",
    "    rotation_angle_yaxis=np.random.uniform(0.0, 2*np.pi, size=20),\n",
    "    rotation_angle_zaxis=np.full(20, 4.04),\n",
    "    \n",
    "    model_name='Nr5a1', \n",
    "    ei_type='e',\n",
    "    tuning_angle=np.linspace(start=0.0, stop=360.0, num=20, endpoint=False),\n",
    ")\n",
    "\n",
    "x, y, z = get_coords(15)\n",
    "l4.add_nodes(\n",
    "    # Parvalbumin inhibitory cells, note these aren't assigned a tuning angle and ei=i\n",
    "    N=15, \n",
    "    \n",
    "    model_type='biophysical',\n",
    "    model_template='ctdb:Biophys1.hoc',\n",
    "    dynamics_params='Pvalb_473862421_params.json',\n",
    "    morphology='Pvalb_473862421_morphology.swc',\n",
    "    model_processing='aibs_perisomatic',\n",
    "    \n",
    "    x=x, y=y, z=z, \n",
    "    rotation_angle_xaxis=0,\n",
    "    rotation_angle_yaxis=np.random.uniform(0.0, 2*np.pi, size=15),\n",
    "    rotation_angle_zaxis=np.random.uniform(0.0, 2*np.pi, size=15),\n",
    "    \n",
    "    model_name='PValb',\n",
    "    ei_type='i',\n",
    ")\n",
    "\n",
    "l4.build()\n",
    "l4.save_nodes(output_dir='network')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note** that in our last call to ```add_nodes()``` we skipped the **tuning_angle** property (referring to the receptive field orientation tuning). The use of **tuning_angle** will be described in more detail in [Tutorial 6](../Ch6_l4model/6.%20The%20L4%20Model.ipynb). This property is more relevant for excitatory L4 neurons than the less selective PValb neurons. BMTK and SONATA gives us the option to have different properities for different node-types even within the same network. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use VND to examine the cells in this model\n",
    "\n",
    "Launch VND by typing `vnd` on the Linux command line.\n",
    "\n",
    "In the Visual Neuronal Dynamics window select, select menu item  **File : Open File with Edges**\n",
    "and choose the file `Ch3_multicells/config.l4.json`.\n",
    "\n",
    "In the Main tab, in the Representations pane:\n",
    "\n",
    "In the list of representations, the single, default selection is:\n",
    "\n",
    "- Selected Neurons: all\n",
    "- Coloring Method: Type\n",
    "- Style: soma\n",
    "\n",
    "With the \"all\" selection highlighted,\n",
    "click \"Representations:Create Rep\" \n",
    "Then with this second representation in the list selected, make these changes (in order):\n",
    "\n",
    "- Selected Neurons: stride 5\n",
    "- Style: morphology_draft\n",
    "\n",
    "\n",
    "This will put a small selection of cells (every 5th cell) into detailed morphology view.  This gives a sense of the system layout, but still allows manipulation of the system at a usable frame rate.\n",
    "\n",
    "Click on the top \"all\" (Type soma) selection in the Representations pane list, then select **Display : Reset View** to view the whole system.\n",
    "\n",
    "\n",
    "Explore the synapse locations with zooming, rotation, and translation.\n",
    "\n",
    "\n",
    "<div>\n",
    "  <img src=\"../images/ch3_l4_stride_10_morpho_draft.png\" width=\"805\" align=\"left\" style=\"margin-left:26px\"/>    \n",
    "</div>\n",
    "<br clear=\"left\">\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building Connections\n",
    "\n",
    "<br>\n",
    "<div>\n",
    "  <img src=\"../images/builder_add_edges.png\" width=\"500\" align=\"left\" style=\"margin-left:5px\"/>    \n",
    "</div>\n",
    "<br clear=\"left\">\n",
    "\n",
    "We can now start creating the rules for recurrent connections. Like with \"Node Types\" we can start by using the ```add_edges()``` method to create multiple \"Edge Types\". However, instead of passing in an integer for the total number of individual edges/synapses, ```add_edges()``` requires that we pass in at minimum:\n",
    "1. A filter or list for the subset of nodes to use as _sources_/_pre-synaptic cells_\n",
    "2. A filter or list for the subset of nodes to use as _targets_/_post-synaptic cells_.\n",
    "3. A rule for how many connections/edges between each source and target cell.\n",
    "\n",
    "For example, imagine we want to create an Edge Type that connects all the excitatory cells to other excitatory cells, where the number of connections is weighted according to their **tuning_angle** property. In this case the **connection_rule** is a function that takes in source and target cell objects (whose properties can be accessed like a regular Python dictionary) and should return an integer 0 or greater. When ```l4.build()``` is called BMTK will utilize this function for all valid source/target pairs of cells.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exc_exc_rule(source, target, max_syns):\n",
    "    \"\"\"Connection rule for exc-->exc neurons, should return an integer 0 or greater\"\"\"\n",
    "    if source['node_id'] == target['node_id']:\n",
    "        # prevent a cell from synapsing with itself\n",
    "        return 0\n",
    "    \n",
    "    # calculate the distance between tuning angles and use it to choose\n",
    "    # number of connections using a binomial distribution.\n",
    "    src_tuning = source['tuning_angle']\n",
    "    trg_tuning = target['tuning_angle']\n",
    "    tuning_dist = np.abs((src_tuning - trg_tuning + 180) % 360 - 180)\n",
    "    probs = 1.0 - (np.max((tuning_dist, 10.0)) / 180.0)\n",
    "    return np.random.binomial(n=max_syns, p=probs)\n",
    "\n",
    "\n",
    "conns = l4.add_edges(\n",
    "    # filter for subpopulation or source and target nodes\n",
    "    source=l4.nodes(ei_type='e'),\n",
    "    target=l4.nodes(ei_type='e'),\n",
    "    \n",
    "    # connection function + any required parameters\n",
    "    connection_rule=exc_exc_rule,\n",
    "    connection_params={'max_syns': 15},\n",
    "    \n",
    "    # edge-type parameters\n",
    "    syn_weight=3.0e-05,\n",
    "    delay=2.0,\n",
    "    dynamics_params='AMPA_ExcToExc.json',\n",
    "    model_template='Exp2Syn',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The properties **syn_weight**, **delay**, **dynamics_params**, and **model_template** are all edge-type properties whose values are shared by every edge/synapse of this type. Like with nodes, we can add properties that are unique for every edge/synapse. But unlike the ```add_nodes()``` method, we can't just pass in a list of size M to ```add_edges()``` (since we won't know how many individual edges the network contains until the connectivity matrix has been calculated).\n",
    "\n",
    "Instead, to add unique properties to individual edges we will call the ```add_properties()``` method. For instance, we can place the synapse locations on the morphology and display them in VND, specified by _afferent_swc_id_ (referring to segments in the 3D morphological reconstruction of the SWC file) and _afferent_section_id_ (referring to the abstracted NEURON representation of the morphology, where sections are unbranched cables). The _afferent_section_pos_ and _afferent_swc_pos_ indicate relative position within the section. ```rand_syn_locations``` will assign these according to the _rule_params_. For a more extensive explanation of morphology parameters, see [3A. Morphology Representation](3A.%20Morphology%20Representation.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bmtk.builder.bionet import rand_syn_locations\n",
    "\n",
    "conns.add_properties(\n",
    "    ['afferent_section_id', 'afferent_section_pos', 'afferent_swc_id', 'afferent_swc_pos'],\n",
    "    rule=rand_syn_locations,\n",
    "    rule_params={\n",
    "        'sections': ['basal', 'apical'], \n",
    "        'distance_range': [30.0, 150.0],\n",
    "        'morphology_dir': 'components/morphologies' \n",
    "    },\n",
    "    dtypes=[int, float, int, float]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For other types of connections, since the source and/or target is an inhibitory cell with no **tuning_angle** property, we'll instead weigh the number of connections based on distance in the x/z plane. \n",
    "The parameter **distance_range** acts as a filter on the randomly selected locations, so setting it to [0.0, 1.0e+20] means essentially no spatial restrictions on where the synapses are placed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def others_conn_rule(source, target, max_syns, max_distance=300.0, sigma=60.0):\n",
    "    if source['node_id'] == target['node_id']:\n",
    "        return 0\n",
    "    \n",
    "    dist = np.sqrt((source['x'] - target['x'])**2 + (source['z'] - target['z'])**2)\n",
    "    if dist > max_distance:\n",
    "        return 0\n",
    "    \n",
    "    prob = np.exp(-(dist/sigma)**2)      # Gaussian fall off with distance\n",
    "    return np.random.binomial(n=max_syns, p=prob)\n",
    "\n",
    "## Create e --> i connections\n",
    "conns = l4.add_edges(\n",
    "    source=l4.nodes(ei_type='e'),\n",
    "    target=l4.nodes(ei_type='i'),\n",
    "    connection_rule=others_conn_rule,\n",
    "    connection_params={'max_syns': 8},\n",
    "    syn_weight=0.0006,\n",
    "    delay=2.0,\n",
    "    dynamics_params='AMPA_ExcToInh.json',\n",
    "    model_template='Exp2Syn',\n",
    ")\n",
    "conns.add_properties(\n",
    "    ['afferent_section_id', 'afferent_section_pos', 'afferent_swc_id', 'afferent_swc_pos'],\n",
    "    rule=rand_syn_locations,\n",
    "    rule_params={\n",
    "        'sections': ['somatic', 'basal'], \n",
    "        'distance_range': [0.0, 1.0e+20],\n",
    "        'morphology_dir': 'components/morphologies' \n",
    "    },\n",
    "    dtypes=[int, float, int, float]\n",
    ")\n",
    "\n",
    "## Create i --> e connections\n",
    "conns = l4.add_edges(\n",
    "    source=l4.nodes(ei_type='i'),\n",
    "    target=l4.nodes(ei_type='e'),\n",
    "    connection_rule=others_conn_rule,\n",
    "    connection_params={'max_syns': 4},\n",
    "    syn_weight=0.07,\n",
    "    delay=2.0,\n",
    "    dynamics_params='GABA_InhToExc.json',\n",
    "    model_template='Exp2Syn',\n",
    ")\n",
    "conns.add_properties(\n",
    "    ['afferent_section_id', 'afferent_section_pos', 'afferent_swc_id', 'afferent_swc_pos'],\n",
    "    rule=rand_syn_locations,\n",
    "    rule_params={\n",
    "        'sections': ['somatic', 'basal', 'apical'], \n",
    "        'distance_range': [0.0, 50.0],\n",
    "        'morphology_dir': 'components/morphologies' \n",
    "    },\n",
    "    dtypes=[int, float, int, float]\n",
    ")\n",
    "\n",
    "## Create i --> i connections\n",
    "conns = l4.add_edges(\n",
    "    source=l4.nodes(ei_type='i'),\n",
    "    target=l4.nodes(ei_type='i'),\n",
    "    connection_rule=others_conn_rule,\n",
    "    connection_params={'max_syns': 4},\n",
    "    syn_weight=0.00015,\n",
    "    delay=2.0,\n",
    "    dynamics_params='GABA_InhToInh.json',\n",
    "    model_template='Exp2Syn',\n",
    ")\n",
    "conns.add_properties(\n",
    "    ['afferent_section_id', 'afferent_section_pos', 'afferent_swc_id', 'afferent_swc_pos'],\n",
    "    rule=rand_syn_locations,\n",
    "    rule_params={\n",
    "        'sections': ['somatic', 'basal', 'apical'], \n",
    "        'distance_range': [0.0, 1.0e+20],\n",
    "        'morphology_dir': 'components/morphologies' \n",
    "    },\n",
    "    dtypes=[int, float, int, float]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the **connection_rule** and **rule_params** functions have not yet been called. Only once we call the ```build()``` method will it utilize these functions to build the connectivity matrix. The ```build()``` process can take a bit of time to complete depending on the number of edges and the complexity of connection rules.\n",
    "\n",
    "\n",
    "<br>\n",
    "<div>\n",
    "  <img src=\"../images/builder_complete_network.png\" width=\"400\" align=\"left\" style=\"margin-left:5px\"/>    \n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "l4.build()\n",
    "l4.save(output_dir='network')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show all the l4 population connections with VND \n",
    "\n",
    "\n",
    "From above VND session\n",
    " \n",
    " In the Connections tab, set:\n",
    " \n",
    "- Source: population == l4\n",
    "- Target: population == l4\n",
    "- Color: pink \n",
    "- Style: simple_edges\n",
    "\n",
    "then click \"Create Connection Rep\".\n",
    "\n",
    "Click on the top \"all\" (Type soma) selection in the Representations pane list, then select **Display : Reset View** to view the whole system.\n",
    "\n",
    "\n",
    "Explore the synapse locations with zooming, rotation, and translation.\n",
    "\n",
    "\n",
    "<div>\n",
    "  <img src=\"../images/ch3_l4_edges.png\" width=\"805\" align=\"left\" style=\"margin-left:26px\"/>    \n",
    "</div>\n",
    "<br clear=\"left\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show the l4 connections from a single cell in VND\n",
    "\n",
    "In above session, hide all representations but the first soma \"all\" representations.\n",
    "\n",
    "If the VND session is getting slow, use **File : Reset VND** (or even quit and relaunch VND) then  **File : Open File with Edges**  `Ch3_multicells/config.l4.json`.\n",
    "\n",
    "Follow the next steps to show the morphology for a single cell (node 1), set colors for different l4 cell types, then show the connections from node 1 to all the cells in l4.\n",
    "\n",
    "In Main tab, Representations pane,\n",
    "set:\n",
    "- Selected Neurons: node_id ==1\n",
    "- Coloring Method == Type\n",
    "- Style: morphology\n",
    "\n",
    "...then click **Create Rep**\n",
    "\n",
    "set:\n",
    "-  Selected Neurons: type == 100\n",
    "- Coloring Method: cyan\n",
    "- Style: soma\n",
    "\n",
    "...then click **Create Rep**\n",
    "\n",
    "set:\n",
    "- Selected Neurons: type == 101\n",
    "- Coloring Method: pink\n",
    "- Style: soma\n",
    "\n",
    "...then click **Create Rep**\n",
    "\n",
    "set:\n",
    "- Selected Neurons: type == 102\n",
    "- Coloring Method: red\n",
    "- Style: soma\n",
    "...then click **Create Rep**\n",
    "\n",
    "set:\n",
    "- Selected Neurons: type == 103\n",
    "- Coloring Method: purple\n",
    "- Style: soma\n",
    "\n",
    "...then click **Create Rep**\n",
    "\n",
    "In Connections window,\n",
    "\n",
    "set:\n",
    "- Source: node_id == 1\n",
    "- Target: population == l4\n",
    "- Color: white\n",
    "- Style: simple_edge\n",
    "- Edge scale: 1\n",
    "\n",
    "... then click **Create Connection Rep**.\n",
    "\n",
    "<div>\n",
    "  <img src=\"../images/ch3_l4_edges_node_1_to_colored_types.png\" width=\"805\" align=\"left\" style=\"margin-left:26px\"/>    \n",
    "</div>\n",
    "<br clear=\"left\">\n",
    "\n",
    "Explore the synapse locations with zooming, rotation, and translation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding Feedforward Stimulus\n",
    "\n",
    "At this point we could go ahead and start running simulations on our L4 network with stimuli such as current clamps, voltage clamps, or even extracellular electrodes. However, to make the model a bit more realistic we are going to want to stimulate it using feedforward synaptic input - just as the mouse visual cortex receives input from the lateral geniculate nucleus (LGN) in the thalamus. \n",
    "\n",
    "We will build another network to model the LGN, made up of \"virtual\" cells on a flat plane covering the visual space (for convenience, the coordinates here reference visual space rather than position within the brain area). The important thing is that the cells have **model_type**=virtual. We are also including other parameters **model_template** and **dynamics_params** to indicate the type of LGN cells (transient ON cells), but these options will be ignored until they are used with FilterNet later. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_coords_plane(ncells, size_x=240.0, size_y=120.0):\n",
    "    xs = np.random.uniform(0.0, size_x, ncells)\n",
    "    ys = np.random.uniform(0.0, size_y, ncells)\n",
    "    return xs, ys\n",
    "    \n",
    "\n",
    "lgn = NetworkBuilder('lgn')\n",
    "\n",
    "x, y = generate_coords_plane(100)\n",
    "lgn.add_nodes(\n",
    "    N=100,\n",
    "    x=x,\n",
    "    y=y,\n",
    "    model_type='virtual',\n",
    "    model_template='lgnmodel:tON',\n",
    "    dynamics_params='tON_TF15.json',\n",
    "    ei_type='e'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we need to connect the LGN cells to the l4 cells. To mimic the real LGN, we want to start by mapping the LGN plane to a topographically corresponding ellipse in the xz plane of our L4 model. For every LGN cell find all l4 cells that are within the ellipse, then select N excitatory cells and M inhibitory cells.\n",
    "\n",
    "<br>\n",
    "<div>\n",
    "  <img src=\"../images/LGN_to_L4_conn_scheme.png\" width=\"800\" align=\"center\" style=\"margin-left:5px\"/>    \n",
    "</div>\n",
    "<br clear=\"left\">\n",
    "\n",
    "This would be very hard to accomplish with the previous **connection_rule** function that is called for every individual source/target pair. Instead we must use a different function signature - BMTK will pass into it 1 source cell and a list of dictionaries of all possible target cells. And the function will now return a list of integers for the number of synapses (including 0 entries) onto each individual target cell.\n",
    "\n",
    "We just have to use the option **iterator**='one_to_all' (other options include 'all_to_one' and the default option 'one_to_one').\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect_lgn_cells(source, targets, max_targets, min_syns=1, max_syns=15, lgn_size=(240, 120),\n",
    "                      l4_radius=400.0, ellipse=(100.0, 500.0)):\n",
    "    # Map the lgn cells from the plane to the circle\n",
    "    x, y = source['x'], source['y']\n",
    "    x = 2*(x / lgn_size[0] - 0.5)\n",
    "    y = 2*(y / lgn_size[1] - 0.5)\n",
    "    src_x = x * np.sqrt(1.0 - (y**2/2.0)) * l4_radius\n",
    "    src_y = y * np.sqrt(1.0 - (x**2/2.0)) * l4_radius\n",
    "\n",
    "    # Find (the indices) of all the target cells that are within the given ellipse, if there are more than max_targets\n",
    "    # then randomly choose them\n",
    "    a, b = ellipse[0]**2, ellipse[1]**2\n",
    "    dists = [(src_x-t['x'])**2/a + (src_y-t['y'])**2/b for t in targets]\n",
    "    valid_targets = np.argwhere(np.array(dists) <= 1.0).flatten()\n",
    "    if len(valid_targets) > max_targets:\n",
    "        valid_targets = np.random.choice(valid_targets, size=max_targets, replace=False)\n",
    "\n",
    "    # Create an array of all synapse count. Most targets will have 0 connection, except for the \"valid_targets\" which\n",
    "    # will have between [min_syns, max_syns] number of connections.\n",
    "    nsyns_arr = np.zeros(len(targets), dtype=int)\n",
    "    for idx in valid_targets:\n",
    "        nsyns_arr[idx] = np.random.randint(min_syns, max_syns)\n",
    "\n",
    "    return nsyns_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conns = lgn.add_edges(\n",
    "    source=lgn.nodes(),\n",
    "    target=l4.nodes(ei_type='e'),\n",
    "    connection_rule = connect_lgn_cells,\n",
    "    connection_params = {'max_targets': 6},\n",
    "    iterator='one_to_all',\n",
    "    model_template='Exp2Syn',\n",
    "    dynamics_params='AMPA_ExcToExc.json',\n",
    "    delay=2.0,\n",
    "    syn_weight=0.0019\n",
    ")\n",
    "conns.add_properties(\n",
    "    ['afferent_section_id', 'afferent_section_pos', 'afferent_swc_id', 'afferent_swc_pos'],\n",
    "    rule=rand_syn_locations,\n",
    "    rule_params={\n",
    "        'sections': ['somatic', 'basal', 'apical'],\n",
    "        'distance_range': [0.0, 1.0e+20],\n",
    "        'morphology_dir': 'components/morphologies'\n",
    "    },\n",
    "    dtypes=[int, float, int, float]\n",
    ")\n",
    "\n",
    "\n",
    "conns = lgn.add_edges(\n",
    "    source=lgn.nodes(),\n",
    "    target=l4.nodes(ei_type='i'),\n",
    "    connection_rule=connect_lgn_cells,\n",
    "    connection_params={'max_targets': 12, 'ellipse': (400.0, 400.0)},\n",
    "    iterator='one_to_all',\n",
    "    model_template='Exp2Syn',\n",
    "    dynamics_params='AMPA_ExcToInh.json',\n",
    "    delay=2.0,\n",
    "    syn_weight=0.003\n",
    ")\n",
    "conns.add_properties(\n",
    "    ['afferent_section_id', 'afferent_section_pos', 'afferent_swc_id', 'afferent_swc_pos'],\n",
    "    rule=rand_syn_locations,\n",
    "    rule_params={\n",
    "        'sections': ['somatic', 'basal', 'apical'],\n",
    "        'distance_range': [0.0, 1.0e+20],\n",
    "        'morphology_dir': 'components/morphologies'\n",
    "    },\n",
    "    dtypes=[int, float, int, float]\n",
    ")\n",
    "\n",
    "\n",
    "lgn.build()\n",
    "lgn.save(output_dir='network')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Spikes for LGN inputs\n",
    "\n",
    "Now that we have LGN virtual cells to synaptically connect and stimulate our L4 model, let's provide some spike trains for our LGN cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from bmtk.utils.reports.spike_trains import PoissonSpikeGenerator\n",
    "from bmtk.analyzer.spike_trains import plot_raster\n",
    "\n",
    "times = np.linspace(0.0, 5.0, 1000)\n",
    "max_rate = 15.0\n",
    "min_rate = 2.0\n",
    "onset = 1.0\n",
    "rates = (max_rate-min_rate)/(1.0 + np.exp(-(times-onset)*3.0)) + min_rate\n",
    "\n",
    "psg = PoissonSpikeGenerator()\n",
    "psg.add(\n",
    "    node_ids='network/lgn_nodes.h5', \n",
    "    firing_rate=rates, \n",
    "    times=times,\n",
    "    population='lgn'\n",
    ")\n",
    "psg.to_sonata('inputs/lgn_spikes.h5')\n",
    "\n",
    "# plot the firing rates\n",
    "plt.plot(times, rates)\n",
    "\n",
    "_ = plot_raster(spikes_file='inputs/lgn_spikes.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up the environment\n",
    "\n",
    "The next step is to set up the directory where we will run our simulation, including the run_bionet.py script, configuration files, and components' files. This has already been setup for you, but if you were going to build the directory from scratch you can run either the following in the command line:\n",
    "\n",
    "```bash\n",
    "  $ python -m bmtk.utils.create_environment                \\\n",
    "                 --config-file config.l4.json              \\\n",
    "                 --overwrite                               \\\n",
    "                 --network-dir network                     \\\n",
    "                 --output-dir output_syns                  \\\n",
    "                 --tstop 3000.0                            \\\n",
    "                 --dt 0.1                                  \\\n",
    "                 --report-vars v                           \\\n",
    "                 --spikes-inputs lgn:inputs/lgn_spikes.h5  \\\n",
    "                 --compile-mechanisms                      \\\n",
    "                 bionet .\n",
    "```\n",
    "\n",
    "or in the notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bmtk.utils.create_environment import create_environment\n",
    "\n",
    "create_environment(\n",
    "    'bionet',\n",
    "    base_dir='.',                      \n",
    "    config_file='config.l4.json',   \n",
    "    network_dir='network',             \n",
    "    output_dir='output' ,       \n",
    "    tstop=3000.0, dt=0.1,              \n",
    "    spikes_inputs=[('lgn', 'inputs/lgn_spikes.h5')],\n",
    "    report_vars=['v'],                 \n",
    "    compile_mechanisms=True,           \n",
    "    # overwrite=True,       \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the simulation\n",
    "\n",
    "We are now ready to run the simulation of our L4 network with LGN stimulation. We can do this in console:\n",
    "\n",
    "```bash\n",
    "$ python run_bionet.py config.l4.json\n",
    "```\n",
    "\n",
    "or in the notebook, as shown below.\n",
    "\n",
    "**Note: on a single core the following simulation can take a few minutes to run.** We can also run this on multiple cores from the terminal using MPI:\n",
    "\n",
    "```bash\n",
    "$ mpirun -np N nrniv -mpi -python run_bionet.py config.l4.json\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bmtk.simulator import bionet\n",
    "\n",
    "conf = bionet.Config.from_json('config.l4.json')\n",
    "conf.build_env()\n",
    "\n",
    "net = bionet.BioNetwork.from_config(conf)\n",
    "sim = bionet.BioSimulator.from_config(conf, network=net)\n",
    "sim.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bmtk.analyzer.spike_trains import plot_raster\n",
    "\n",
    "_ = plot_raster(config_file='config.l4.json', group_by='model_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bmtk.analyzer.compartment import plot_traces\n",
    "\n",
    "# Plot the membrane potential trace\n",
    "_ = plot_traces(config_file='config.l4.json', node_ids = [45, 65], report_name='v_report')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also get spiking statistics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bmtk.analyzer.spike_trains import spike_statistics\n",
    "\n",
    "spike_statistics(spikes_file='output/spikes.h5', simulation=sim, group_by='model_name')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show spike activity animation in VND\n",
    "\n",
    "Launch VND by typing `vnd` on the Linux command line.\n",
    "\n",
    "In the Visual Neuronal Dynamics window select, select menu item  **File : Open File with Edges**\n",
    "and choose the file `Ch3_multicells/config.l4.json`.\n",
    "\n",
    "In the Main tab, in the Representations pane:\n",
    "\n",
    "In the list of representations, the single, default selection is:\n",
    "\n",
    "- Selected Neurons: all\n",
    "- Coloring Method: Type\n",
    "- Style: soma\n",
    "\n",
    "Select menu item  **File : Add File with Spikes** and choose `Ch3_multicells/output/spikes.h5`\n",
    "\n",
    "In the Activity window, set:\n",
    "\n",
    "- Population:l4\n",
    "\n",
    "Click **Update Selection** and set:\n",
    "- Color: blue\n",
    "- Sphere Scale: 10\n",
    "- Sphere Resolution: 5\n",
    "- Step: 5\n",
    "- Time window: 10\n",
    "\n",
    "If no structures are showing, you may need to select **Display : Reset View**.  (Or even, in the Main tab Representations pane,select the soma, \"all\" representation, then select **Display : Reset View**.)\n",
    "\n",
    "Drag the time slider left and right ,  drag it back to the far left, then press the right-pointing play button to play through the series of spikes.  Change speed with the Speed slider.\n",
    "\n",
    "\n",
    "Direct link to <a href=\"http://www.ks.uiuc.edu/~barryi/bmtk_allen_workshop_2022/ch3-spikes-soma-tilted-persp.mp4\"> l4 spikes (tilted perspective) video </a>\n",
    "\n",
    "\n",
    "<video controls>\n",
    "  <source src=\"http://www.ks.uiuc.edu/~barryi/bmtk_allen_workshop_2022/ch3-spikes-soma-tilted-persp.mp4\" type=\"video/mp4\">\n",
    "  This browser does not display the video tag.\n",
    "</video>\n",
    "    </div>\n",
    "<br clear=\"left\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VND l4 spike activity movie with morphology\n",
    "\n",
    "Another view of the spike data can be generated using cell morphology.  With the currrent version of VND, this takes about 20 minutes to generate, much too slow to get a sense of the animation when viewed live.  Here is a screencast of a VND session showing this animation sped up 45x. \n",
    "\n",
    "Direct link to <a href=\"http://www.ks.uiuc.edu/~barryi/bmtk_allen_workshop_2022/ch3-spikes-l4-morpho-x45.mp4\"> ch3-spikes-morpho-x45 mp4 video </a>\n",
    "\n",
    "\n",
    "<video controls>\n",
    "  <source src=\"http://www.ks.uiuc.edu/~barryi/bmtk_allen_workshop_2022/ch3-spikes-l4-morpho-x45.mp4\" type=\"video/mp4\">\n",
    "  This browser does not display the video tag.\n",
    "</video>\n",
    "    </div>\n",
    "<br clear=\"left\">\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Up Next\n",
    "\n",
    "We have shown how to build and simulate a toy model of the mouse cortex using multi-compartment biophysically realistic cell models. But as mentioned in the introduction BMTK, SONATA, and VND can work across multiple levels of resolutions. In the next chapter we will show how using the same API with only some minor adjustments we can convert or rebuild the same model using point neuron and even population level models.\n",
    "\n",
    "\n",
    "[**Proceed to Chapter 4**](../Ch4_pointnet/4.%20Multipopulation%20GLIF%20model.ipynb)\n",
    "\n",
    "Continue below if you would like to try adding a less computationally-intensive surround consisting of point LIF neurons in the same model as our core of biophysically detailed neurons. In general, this could be useful if you need to simulate many neurons at a low level of detail interacting with some neurons of interest at a high level of detail."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [OPTIONAL] Adding Surrounding Neurons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a core set of 75 neurons we are interested in simulating and analyzing. They receive inputs from the LGN and they are recurrently connected, but don't have any neighboring neurons. This can be unrealistic and could produce unintended boundary artifacts. We could place additional biophysically detailed neurons on the periphery of our L4 column - but this would make the model more complex than it has to be, increasing the time and processing we will need to run it.\n",
    "\n",
    "Instead, we can add very simple integrate-and-fire neurons to our network. These can mimic the interaction of surrounding neuronal activity - without adding too much complexity in terms of fitting the weights and the computational requirements to run the model.\n",
    "\n",
    "<br>\n",
    "<div>\n",
    "  <img src=\"../images/l4_with_periphery.png\" width=\"700\" align=\"left\" style=\"margin-left:5px\"/>    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could go back and rebuild the l4 network with these integrate-and-fire neurons, but for easy of use we'll just create it as a separate network and connect it up in the config.\n",
    "\n",
    "We'll call our network \"lif\" for leaky integrate-and-fire. We'll add a population of excitatory and inhibitory LIF neurons but noting the following:\n",
    "* **model_type** is now set to \"point_neuron\" \n",
    "* There is no need for **morphology** or **model_processing**, since these are simple point-neuron models that don't have any associated morphology.\n",
    "* In **model_template** we'll set it so they are using NEURON's built-in [IntFire1 type cells](https://www.neuron.yale.edu/neuron/static/py_doc/modelspec/programmatic/mechanisms/mech.html#IntFire1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lif = NetworkBuilder('lif')\n",
    "\n",
    "# place neurons on outer ring\n",
    "x, y, z = get_coords(80, radius_min=400.0, radius_max=800.0)\n",
    "lif.add_nodes(\n",
    "    N=80, \n",
    "    x=x, y=y, z=z,\n",
    "    model_type='point_neuron',\n",
    "    model_template='nrn:IntFire1',\n",
    "    dynamics_params='IntFire1_exc_1.json',\n",
    "    model_name='LIF_exc', \n",
    "    ei_type='e',\n",
    ")\n",
    "\n",
    "x, y, z = get_coords(20, radius_min=400.0, radius_max=800.0)\n",
    "lif.add_nodes(\n",
    "    N=20, \n",
    "    x=x, y=y, z=z,\n",
    "    model_type='point_neuron',\n",
    "    model_template='nrn:IntFire1',\n",
    "    dynamics_params='IntFire1_inh_1.json',\n",
    "    model_name='LIF_inh', \n",
    "    ei_type='i',\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will connect our LIF neurons to our L4 neurons. Previously we used the Builder's ```add_properties()``` to explicity store the target synaptic locations in the _edges.h5_ file. This time we will store the **target_sections** and **distance_range** as edge-type properties. BMTK has a special feature that when it sees these two arguments in the edge-type properties it will use them to randomly create synapses during the simulation processes. This will add a bit of randomness when we run the simulations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lif.add_edges(\n",
    "    source=lif.nodes(ei_type='e'), target=l4.nodes(ei_type='e'),\n",
    "    #connection_rule=8,\n",
    "    connection_rule = lambda *_: np.random.randint(0, 8),\n",
    "    syn_weight=0.00002,    \n",
    "    delay=2.0,\n",
    "    distance_range=[30.0, 150.0],\n",
    "    target_sections=['somatic', 'basal', 'apical'],\n",
    "    dynamics_params='AMPA_ExcToExc.json',\n",
    "    model_template='Exp2Syn'\n",
    ")\n",
    "\n",
    "lif.add_edges(\n",
    "    source=lif.nodes(ei_type='e'), target=l4.nodes(ei_type='i'),\n",
    "    connection_rule = lambda *_: np.random.randint(0, 5),\n",
    "    syn_weight=0.015,\n",
    "    delay=2.0,\n",
    "    distance_range=[30.0, 150.0],\n",
    "    target_sections=['somatic', 'basal'],\n",
    "    dynamics_params='AMPA_ExcToInh.json',\n",
    "    model_template='Exp2Syn'\n",
    ")\n",
    "\n",
    "lif.add_edges(\n",
    "    source=lif.nodes(ei_type='i'), target=l4.nodes(ei_type='e'),\n",
    "    connection_rule = lambda *_: np.random.randint(0, 5),\n",
    "    syn_weight=0.085,\n",
    "    delay=2.0,\n",
    "    distance_range=[0.0, 50.0],\n",
    "    target_sections=['somatic', 'basal', 'apical'],\n",
    "    dynamics_params='GABA_InhToExc.json',\n",
    "    model_template='Exp2Syn'\n",
    ")\n",
    "\n",
    "lif.add_edges(\n",
    "    source=lif.nodes(ei_type='i'), target=l4.nodes(ei_type='i'),\n",
    "    connection_rule = lambda *_: np.random.randint(0, 5),\n",
    "    syn_weight=0.085,\n",
    "    delay=2.0,\n",
    "    distance_range=[0.0, 1e+20],\n",
    "    target_sections=['somatic', 'basal'],\n",
    "    dynamics_params='GABA_InhToInh.json',\n",
    "    model_template='Exp2Syn'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_conn_rule(source, target, max_syns):\n",
    "    if source['node_id'] == target['node_id']:\n",
    "        return 0\n",
    "    \n",
    "    return np.random.randint(0, max_syns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we connect our L4 cells to our LIF neurons, as-well-as our LIF neurons to each other. Since we are connecting to neurons that are just a point in space it doesn't make sense to specify the synaptic locations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect L4 --> LIFs\n",
    "lif.add_edges(\n",
    "    source=l4.nodes(ei_type='e'), target=lif.nodes(),\n",
    "    connection_rule=lambda *_: np.random.randint(0, 12),\n",
    "    syn_weight=0.010,\n",
    "    delay=2.0,\n",
    "    dynamics_params='instantaneousExc.json',\n",
    "    model_template='Exp2Syn'\n",
    ")\n",
    "\n",
    "lif.add_edges(\n",
    "    source=l4.nodes(ei_type='i'), target=lif.nodes(),\n",
    "    connection_rule=lambda *_: np.random.randint(0, 12),\n",
    "    syn_weight=0.010,\n",
    "    delay=2.0,\n",
    "    dynamics_params='instantaneousInh.json',\n",
    "    model_template='Exp2Syn'\n",
    ")\n",
    "\n",
    "# Connect LIFs --> LIFS\n",
    "lif.add_edges(\n",
    "    source=lif.nodes(ei_type='e'), target=lif.nodes(),\n",
    "    connection_rule=simple_conn_rule,\n",
    "    connection_params={'max_syns': 12},\n",
    "    #connection_rule=lambda *_: np.random.randint(0, 12),\n",
    "    syn_weight=0.0000,  \n",
    "    delay=2.0,\n",
    "    dynamics_params='instantaneousExc.json',\n",
    "    model_template='Exp2Syn'\n",
    ")\n",
    "\n",
    "lif.add_edges(\n",
    "    source=lif.nodes(ei_type='i'), target=lif.nodes(),\n",
    "    connection_rule=simple_conn_rule,\n",
    "    connection_params={'max_syns': 12},\n",
    "    syn_weight=0.050,\n",
    "    delay=2.0,\n",
    "    dynamics_params='instantaneousInh.json',\n",
    "    model_template='Exp2Syn'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lif.build()\n",
    "lif.save(output_dir='network')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the l4 and LIF system wtih VND\n",
    "\n",
    "Launch VND by typing `vnd` on the Linux command line.\n",
    "\n",
    "In the Visual Neuronal Dynamics window select, select menu item  **File : Open File with Edges**\n",
    "and choose the file `Ch3_multicells/config.l4_with_lifs.json`.\n",
    "\n",
    "In the Main tab, in the Representations pane:\n",
    "\n",
    "In the list of representations, after loading, the   single, default selection is:\n",
    "\n",
    "- Selected Neurons: population = lif\n",
    "- Coloring Method: Type\n",
    "- Style: soma\n",
    "\n",
    "In the Representations window, click **Create rep** then set:\n",
    "\n",
    "- Selected Neurons: population = l4\n",
    "- Coloring Method: Type\n",
    "- Style: morphology\n",
    "\n",
    "\n",
    "Select the top \"population == lif\" representation in the list, then select **Display :: Reset View\"\n",
    "\n",
    "We will reposition the scene with the morphology view hidden, find a good position, then show the morphology representation.\n",
    "\n",
    "Select the \"population = l4\" representation, click Show/Hide to hide. The selection list text should appear in red.\n",
    "\n",
    "Click **Display :: Perspective\"**, then reposition the scene using the mouse.\n",
    "\n",
    "When at desired location, be sure the \"population = l4\" representation is selected, then click Show/Hide to show.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "  <img src=\"../images/l4-morpho-lifs-soma-tach.png\" width=\"805\" align=\"left\" style=\"margin-left:26px\"/>    \n",
    "</div>\n",
    "<br clear=\"left\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Building the LIF neuron network will create 4 sets of SONATA network files:\n",
    "1. We have the **LIF nodes**\n",
    "2. The SONATA network files for the **LIF --> L4** connections.\n",
    "3. The SONATA network files for the **L4 --> LIF** connections.\n",
    "4. The SONATA network files for the **LIF --> LIF** connnections.\n",
    "\n",
    "(note: There are options to store all of them in one single file - but by default, and in our experience for ease of use during the simulation, the BMTK Builder will split them across multiple files)\n",
    "\n",
    "We could call ```bmtk.utils.create_environment``` like we do above to create a new SONATA configuration file. Or alternatively we can just copy the previous config and update the \"network\" section to include the newly created SONATA network files, like below.\n",
    "\n",
    "<br>\n",
    "<div>\n",
    "  <img src=\"../images/ch3_circuit_config_w_lifs_highlighted.png\" width=\"800\" align=\"left\" style=\"margin-left:5px\"/>    \n",
    "</div>\n",
    "<br clear=\"left\">\n",
    "\n",
    "We call our new configuration file *config.l4_with_lifs.json*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The three sets of connections are shown below in VND.  The l4 to l4 connections are in blue, lif to l4 in orange, and l4 to lif in silver.\n",
    "\n",
    "<div>\n",
    "  <img src=\"../images/ch3-connection-sets.png\" width=\"805\" align=\"left\" style=\"margin-left:26px\"/>    \n",
    "</div>\n",
    "<br clear=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now run our model as before. **Note: on a single core the following simulation can take a few minutes to run.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Will reset BioNet and the NEURON simulator. Required if we want\n",
    "# to run the simulator multiple times in the same notebook.\n",
    "bionet.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bmtk.simulator import bionet\n",
    "\n",
    "conf = bionet.Config.from_json('config.l4_with_lifs.json')\n",
    "\n",
    "conf.build_env()\n",
    "net = bionet.BioNetwork.from_config(conf)\n",
    "sim = bionet.BioSimulator.from_config(conf, network=net)\n",
    "sim.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "This time, when plotting the spiking activity, we have to indicate the population that we wish to show with the _population_ option:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plot_raster(config_file='config.l4_with_lifs.json', population='l4', group_by='model_name')\n",
    "_ = plot_raster(config_file='config.l4_with_lifs.json', population='lif', group_by='model_name')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show spike activity animation with LIFS animation\n",
    "\n",
    "Launch VND by typing `vnd` on the Linux command line.\n",
    "\n",
    "In the Visual Neuronal Dynamics window select, select menu item  **File : Open File with Edges**\n",
    "and choose the file `Ch3_multicells/config.l4_with_lifs.json`.\n",
    "\n",
    "In the Main tab, in the Representations pane:\n",
    "\n",
    "In the list of representations, after loading, change the to single, default selection to:\n",
    "\n",
    "- Selected Neurons: population == 14\n",
    "- Coloring Method: red\n",
    "- Style: soma\n",
    "\n",
    "Click **Create Representation**\n",
    "\n",
    "- Selected Neurons: population == lif\n",
    "- Coloring Method: green\n",
    "- Style: soma\n",
    "\n",
    "Select menu item  **File : Add File with Spikes** and choose `Ch3_multicells/output_with_lifs/spikes.h5`\n",
    "\n",
    "\n",
    "In the Activity tab, set:\n",
    "\n",
    "- Population: l4\n",
    "\n",
    "Click **Update Selection**\n",
    "\n",
    "set:\n",
    "- Color: blue\n",
    "- Sphere Scale: 10\n",
    "- Sphere Resolution: 5\n",
    "- Step: 1\n",
    "- Time window: 10\n",
    "\n",
    "If no sturctures are showing, you may need to select **Display : Reset View**.  (Or even, in the Main tab Representations pane,select the soma, \"all\" representation, then select **Display : Reset View**.)\n",
    "\n",
    "Press the right-pointing play button to animate the activity.  Other options: Drag the time slider left and right. Change speed with the Speed slider.\n",
    "\n",
    "Now show the same for population lif:\n",
    "\n",
    "In the Activity tab, set\n",
    "\n",
    "- Population: lif\n",
    "\n",
    "Press the right-pointing play button to animate the LIF activity.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Direct link to <a href=\"http://www.ks.uiuc.edu/~barryi/bmtk_allen_workshop_2022/ch3-with-lifs-spikes-of-l4.mp4\"> l4 spikes,  with-lifs model,  mp4 video </a>\n",
    "\n",
    "Direct link to <a href=\"http://www.ks.uiuc.edu/~barryi/bmtk_allen_workshop_2022/ch3-with-lifs-spikes-of-lif.mp4\"> lif spikes, with-lifs model, mp4 video </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [OPTIONAL] Deep Dive into SONATA Nodes and Edges Format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have shown how to build multi-cells heterogeneous network models, let's take a look at the SONATA nodes and edges files and learn about how they are formatted, in case you want to implement the SONATA format yourself.\n",
    "\n",
    "#### nodes\n",
    "\n",
    "If we open up one of our _nodes.h5_ files using a tool like HDFView or ViTables we can see they all have a format like the following:\n",
    "\n",
    "<br>\n",
    "<div>\n",
    "  <img src=\"../images/nodes_sonata_layout.png\" width=\"950\" align=\"left\" style=\"margin-left:10px\"/>    \n",
    "</div>\n",
    "<br clear=\"left\">\n",
    "\n",
    "* We see it always starts with the path /nodes/$<$population$>$/, where $<$population$>$ is the name we give to the set of nodes.\n",
    "\n",
    "\n",
    "* All individual nodes/cell are assigned a unique _node_id_ within the population. These node_ids are not global and the other populations will almost surely have overlapping ids, hence it's important that each node is uniquely recognized by ($<$population$>$, node_id). \n",
    "\n",
    "\n",
    "* Each node has an assigned _node_type_id_ which point to the global Node-Type (Cell Type) properties. The node_type properties are saved in a easy to read and modify _node_types.csv_ table like the following:\n",
    "\n",
    "<br>\n",
    "<div>\n",
    "  <img src=\"../images/node_types_sonata_layout.png\" width=\"820\" align=\"left\" style=\"margin-left:30px\"/>    \n",
    "</div>\n",
    "<br clear=\"left\">\n",
    "\n",
    "* Each individual node/cell may have additional properties; these are stored in an HDF5 subgroup.\n",
    "\n",
    "In the simplest case we can think of each node as having the following format as they relate to their Node Type and individual node properties:\n",
    "\n",
    "<br>\n",
    "<div>\n",
    "  <img src=\"../images/sonata_hdf5_format_no_groups.png\" width=\"800\" align=\"left\" style=\"margin-left:5px\"/>    \n",
    "</div>\n",
    "<br clear=\"left\">\n",
    "\n",
    "The only issue is that it's possible to have different neuronal models that require different parameters. Sometimes a parameter will have different data types and meanings: ex. $\\alpha$ may be unsigned integers for one group of neurons, while for another group of neurons the $\\alpha$ parameter is expecting a float. This is where the _group_id_ and _group_index_ columns come in, allowing us to assign individual neurons to only their appropriate set of parameters:\n",
    "\n",
    "<br>\n",
    "<div>\n",
    "  <img src=\"../images/sonata_hdf5_format_w_groups.png\" width=\"800\" align=\"left\" style=\"margin-left:5px\"/>    \n",
    "</div>\n",
    "<br clear=\"left\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Edges\n",
    "\n",
    "![](../images/edges_sonata_layout.png)\n",
    "\n",
    "We can see that the edges file looks very similar to the nodes, with some minor distinctions:\n",
    "\n",
    "* The edges inside the HDF5 start with path /edges/$<$population$>$, where $<$population$>$ is any arbitary name we give this set of edges (The NetworkBuilder will infer a name unless explicity stated).\n",
    "\n",
    "\n",
    "* Instead of _edge_id_, each edge is identified by the _node_id_ of the source cell (_source_node_id_ table) and target cell (_target_node_id_ table).\n",
    "  * For any two cells A and B, the connection(s) A --> B may occur 0, 1, or more times. The format is a multigraph structure.\n",
    "  * Both _source_node_id_ and _target_node_id_ have attributes \"node_population\" which is the name of the population of nodes for the source and for the target neurons. All source nodes must belong to the same population, and similarly all target nodes must also belong to the same population (although the two may be different).\n",
    "\n",
    "\n",
    "* The format includes an optional group called _indices_ which contains lookup tables for determining all indices of any arbitary source_node_id, target_node_id, or edge_type_id in $O(1)$ time.\n",
    "\n",
    "\n",
    "* Individual edge parameters are grouped as described above with nodes, but called _edge_group_id_ and _edge_group_index_ instead of _node_group_id_ and _node_group_index_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[**Proceed to Chapter 4**](../Ch4_pointnet/4.%20Multipopulation%20GLIF%20model.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bmtk-py3.11",
   "language": "python",
   "name": "bmtk-py3.11"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
