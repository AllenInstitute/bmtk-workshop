{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0477c1f-ba3f-48bf-9510-c95a59f49da4",
   "metadata": {},
   "source": [
    "# Advanced methods for driving your network with synapic spike-trains"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cacc6a76-0928-42dd-9257-009a3a628810",
   "metadata": {},
   "source": [
    "BMTK is designed with the goal of building and simulating large-scale, realistic models of the nervous system. An important part for most of these realistic simulations is being able to reacreate the kinds of synaptic input you would expect to see in-vivo. And in order to achieve that modelers need to be able to generate the relevant spike-trains that drive the synpatic stimuli of our simulations.\n",
    "\n",
    "We have other tutorials that demonstrate how to generate realistic stimli using [FilterNet](). And we have also shown how to use the BMTK [SpikeTrain]() and [PoissonSpikeTrain]() class to generate input spike-trains. In these cases it requires users generate SONATA spike-train files before running their simulations. But BMTK also always different methods for users to generate and import spike-train stimuli into their simulations; including using other formats besides SONATA, importing experimental data, as-well-as more fine-grained control of how and where cells within a network recive synaptic stimuli.\n",
    "\n",
    "We will cover some of such methods in the tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e7cd5bb-39cb-4a78-99f1-0db8e4b15d19",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Example: Using spikes from CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6864052b-dd7c-49c7-ab77-f7af106c8bbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "76baf2be-28b2-4944-981b-d7e12fad5578",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Example: Dynamically generating custom spike-trains"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e1860a4-4702-4e6c-b839-5d4372acd95b",
   "metadata": {},
   "source": [
    "Having to pregenerate spike-trains for you simulations inside a hdf5 or CSV file is computationally efficent and makes your results easier to reproduce and share. However, at times it may be beneificial for users to generate spike-trains dynamically during each simulation. If you are doing quick simulation and spot-checks it can be cumbersome having to regenerate a file beforehand. Or if a user is running thousand of simulations, or doing some kind of gradient search, the cost of having to create potentially thousand of spike files beforehand may not be reasonable.\n",
    "\n",
    "BMTK also allows modlers the option to create their own special function which will generate new spike-trains at the start of each simulation. To do so, you only need to make changes to the configuration for a \"spikes\" input so that the **module** is set to value `function`, and instead of spikes_input you specify a **spikes_function** parameter that will be the name of your custom function\n",
    "\n",
    "```json\n",
    "\"inputs\": {\n",
    "    \"LGN_spikes_sonata\": {\n",
    "        \"input_type\": \"spikes\",\n",
    "        \"module\": \"function\",\n",
    "        \"spikes_function\": \"my_spikes_generator\",\n",
    "        \"node_set\": \"LGN\"\n",
    "    }\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a677788-8993-4612-b595-51c4bff5ba30",
   "metadata": {},
   "source": [
    "For BMTK to know where to find the `my_spikes_generator` you must then use the `@spikes_generator` at the top of a given function in your run_bmtk.py script (or any python file imported into run script). In the below example we use the following to return spike trains for every cell in the `LGN` node_set to fire at a constant rate (although different rates for differnt models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8014e00c-b6b8-42c9-a37b-13df612ff431",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bmtk.simulator.bionet.io_tools import io\n",
    "from bmtk.simulator.bionet import spikes_generator\n",
    "import numpy as np\n",
    "\n",
    "@spikes_generator\n",
    "def my_spikes_generator(node, sim):\n",
    "    io.log_info(f'Generating custom spike trains for {node.node_id} from {node.population_name}')\n",
    "    if node['pop_name'] == 'tON':\n",
    "        return np.arange(100.0, sim.tstop, step=sim.dt*10)\n",
    "    elif node['pop_name'] == 'tOFF':\n",
    "        return np.arange(100.0, sim.tstop, step=sim.dt*20)\n",
    "    else:\n",
    "        return []\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f07bf1-fc89-46cb-b23f-35fe33c0a041",
   "metadata": {},
   "source": [
    "* All `spikes_generator` functions must have parameters `node` and `sim`\n",
    "  * `node` allow you to access information about each node/cell like a dictionary.\n",
    "  * `sim` is a class containing information about a current simulation, including information like start time (`sim.tstart`), stop_time (`sim.tstop`), step size (`sim.dt`) among other properties.\n",
    "* The `spikes_generator` should return either a list or array of timestamps, in milliseconds, for each node.\n",
    "* For good measure, we include logging statement. This is not required, but is good for debugging and making sure our custom function is being called.\n",
    "\n",
    "When the simulation is ran the `my_spikes_generator` function will be called once for each node in the specified **node_set**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36732033-c4f4-4c36-994c-b2ec5ef44c86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-04 12:27:30,158 [INFO] Created log file\n",
      "2024-05-04 12:27:30,258 [INFO] Building cells.\n",
      "2024-05-04 12:27:41,412 [INFO] Building recurrent connections\n",
      "2024-05-04 12:27:41,462 [INFO] Building virtual cell stimulations for LGN_spikes_sonata\n",
      "2024-05-04 12:27:41,492 [INFO] Generating custom spike trains for 0 from LGN\n",
      "2024-05-04 12:27:41,501 [INFO] Generating custom spike trains for 28 from LGN\n",
      "2024-05-04 12:27:41,503 [INFO] Generating custom spike trains for 27 from LGN\n",
      "2024-05-04 12:27:41,504 [INFO] Generating custom spike trains for 14 from LGN\n",
      "2024-05-04 12:27:41,506 [INFO] Generating custom spike trains for 2 from LGN\n",
      "2024-05-04 12:27:41,507 [INFO] Generating custom spike trains for 38 from LGN\n",
      "2024-05-04 12:27:41,509 [INFO] Generating custom spike trains for 26 from LGN\n",
      "2024-05-04 12:27:41,510 [INFO] Generating custom spike trains for 15 from LGN\n",
      "2024-05-04 12:27:41,512 [INFO] Generating custom spike trains for 25 from LGN\n",
      "2024-05-04 12:27:41,514 [INFO] Generating custom spike trains for 16 from LGN\n",
      "2024-05-04 12:27:41,516 [INFO] Generating custom spike trains for 24 from LGN\n",
      "2024-05-04 12:27:41,519 [INFO] Generating custom spike trains for 17 from LGN\n",
      "2024-05-04 12:27:41,521 [INFO] Generating custom spike trains for 1 from LGN\n",
      "2024-05-04 12:27:41,524 [INFO] Generating custom spike trains for 39 from LGN\n",
      "2024-05-04 12:27:41,527 [INFO] Generating custom spike trains for 23 from LGN\n",
      "2024-05-04 12:27:41,531 [INFO] Generating custom spike trains for 18 from LGN\n",
      "2024-05-04 12:27:41,533 [INFO] Generating custom spike trains for 12 from LGN\n",
      "2024-05-04 12:27:41,537 [INFO] Generating custom spike trains for 22 from LGN\n",
      "2024-05-04 12:27:41,541 [INFO] Generating custom spike trains for 29 from LGN\n",
      "2024-05-04 12:27:41,544 [INFO] Generating custom spike trains for 11 from LGN\n",
      "2024-05-04 12:27:41,549 [INFO] Generating custom spike trains for 5 from LGN\n",
      "2024-05-04 12:27:41,551 [INFO] Generating custom spike trains for 35 from LGN\n",
      "2024-05-04 12:27:41,554 [INFO] Generating custom spike trains for 6 from LGN\n",
      "2024-05-04 12:27:41,559 [INFO] Generating custom spike trains for 36 from LGN\n",
      "2024-05-04 12:27:41,563 [INFO] Generating custom spike trains for 34 from LGN\n",
      "2024-05-04 12:27:41,566 [INFO] Generating custom spike trains for 7 from LGN\n",
      "2024-05-04 12:27:41,571 [INFO] Generating custom spike trains for 4 from LGN\n",
      "2024-05-04 12:27:41,577 [INFO] Generating custom spike trains for 33 from LGN\n",
      "2024-05-04 12:27:41,579 [INFO] Generating custom spike trains for 8 from LGN\n",
      "2024-05-04 12:27:41,585 [INFO] Generating custom spike trains for 32 from LGN\n",
      "2024-05-04 12:27:41,591 [INFO] Generating custom spike trains for 9 from LGN\n",
      "2024-05-04 12:27:41,600 [INFO] Generating custom spike trains for 37 from LGN\n",
      "2024-05-04 12:27:41,605 [INFO] Generating custom spike trains for 31 from LGN\n",
      "2024-05-04 12:27:41,609 [INFO] Generating custom spike trains for 10 from LGN\n",
      "2024-05-04 12:27:41,610 [INFO] Generating custom spike trains for 30 from LGN\n",
      "2024-05-04 12:27:41,638 [INFO] Generating custom spike trains for 3 from LGN\n",
      "2024-05-04 12:27:41,643 [INFO] Generating custom spike trains for 19 from LGN\n",
      "2024-05-04 12:27:41,648 [INFO] Generating custom spike trains for 13 from LGN\n",
      "2024-05-04 12:27:41,655 [INFO] Generating custom spike trains for 21 from LGN\n",
      "2024-05-04 12:27:41,661 [INFO] Generating custom spike trains for 20 from LGN\n",
      "2024-05-04 12:27:43,969 [INFO] Running simulation for 2000.000 ms with the time step 0.100 ms\n",
      "2024-05-04 12:27:43,970 [INFO] Starting timestep: 0 at t_sim: 0.000 ms\n",
      "2024-05-04 12:27:43,970 [INFO] Block save every 5000 steps\n",
      "2024-05-04 12:28:06,567 [INFO]     step:5000 t_sim:500.00 ms\n",
      "2024-05-04 12:28:31,353 [INFO]     step:10000 t_sim:1000.00 ms\n",
      "2024-05-04 12:28:56,490 [INFO]     step:15000 t_sim:1500.00 ms\n",
      "2024-05-04 12:29:22,678 [INFO]     step:20000 t_sim:2000.00 ms\n",
      "2024-05-04 12:29:22,713 [INFO] Simulation completed in 98.74 seconds \n"
     ]
    }
   ],
   "source": [
    "from bmtk.simulator import bionet\n",
    "\n",
    "bionet.reset()\n",
    "conf = bionet.Config.from_json('config.spikes_generator.json')\n",
    "conf.build_env()\n",
    "\n",
    "net = bionet.BioNetwork.from_config(conf)\n",
    "sim = bionet.BioSimulator.from_config(conf, network=net)\n",
    "sim.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2fbd76-66df-405e-acb2-57a843711405",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ce4e0aca-0600-4b82-87f0-151f168e2de9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Example: Incorporating real data with NWB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a0a55bc-a592-4778-9f6d-0862da876721",
   "metadata": {},
   "source": [
    "While you can use tools like FilterNet or PoissonSpikeGenerator to create theoretical-to-realistic synaptic stimuli onto a network from a variety of different modes. But better yet, when actual experimental data is available, it is often possible to just use that. Especially as as more-and-more experimental electrophysiological data sets are being made publically available through resources like [DANDI](https://dandiarchive.org/) or [The Allen Brain Observatory](https://portal.brain-map.org/circuits-behavior/visual-coding-neuropixels) we will want to not only use such data as a base-line for validating and comparing our models, but to actually use the data within specific simulations. For example, when modeling a network of one population and/or region, we will want use recordings of surrounding cells to help excite and inhibit our cells in a more realistic manner.\n",
    "\n",
    "Traditionally a major issue with using encorporating experimental ephys data into simulations is trying to parse the wide variety of different ways the data was stored. Luckily, the [Neurodata Without Borders (NWB)](https://www.nwb.org/) has developed a field-adopted format for storing experimental data. BMTK can take these files and automatically insert them into simulations.\n",
    "\n",
    "In this example we will take the previous model of the Mouse Primary Visual Cortex and add inputs that we know come from higher cortical regions (in this case just the VisL and Hippocampal regions) along with the input from the LGN. For these added regions, we will use actual neuropixels recordings of activity from the region during drifting gratings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd7df1db-fa11-45e9-ba96-f803a2e7d210",
   "metadata": {},
   "source": [
    "### Step 1: Download the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d183688f-c1fd-477d-ad34-cb91106b0b9b",
   "metadata": {},
   "source": [
    "First step is to find experimental NWB that includes spiking events. For our example we will use data from Allen Institute Visual Coding Data downloaded using the AllenSDK. We will get a three experimental sessions that we know contains recordings the the VisL and hippocamus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f79d70f-b028-4e17-8991-26f54ae130db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:downloading a 2723.916MiB file from http://api.brain-map.org//api/v2/well_known_file_download/1026124469\n",
      "Downloading: 100%|████████████████████████████████████████████████████████| 2.86G/2.86G [00:25<00:00, 111MB/s]\n",
      "/local1/.local/miniconda-23.10.0/envs/bmtk-py3.10/lib/python3.10/site-packages/hdmf/utils.py:668: UserWarning: Ignoring cached namespace 'hdmf-common' version 1.1.3 because version 1.8.0 is already loaded.\n",
      "  return func(args[0], **pargs)\n",
      "/local1/.local/miniconda-23.10.0/envs/bmtk-py3.10/lib/python3.10/site-packages/hdmf/utils.py:668: UserWarning: Ignoring cached namespace 'core' version 2.2.2 because version 2.6.0-alpha is already loaded.\n",
      "  return func(args[0], **pargs)\n",
      "WARNING:root:downloading a 2731.587MiB file from http://api.brain-map.org//api/v2/well_known_file_download/1026124743\n",
      "Downloading: 100%|████████████████████████████████████████████████████████| 2.86G/2.86G [00:25<00:00, 113MB/s]\n",
      "/local1/.local/miniconda-23.10.0/envs/bmtk-py3.10/lib/python3.10/site-packages/hdmf/utils.py:668: UserWarning: Ignoring cached namespace 'hdmf-common' version 1.1.3 because version 1.8.0 is already loaded.\n",
      "  return func(args[0], **pargs)\n",
      "/local1/.local/miniconda-23.10.0/envs/bmtk-py3.10/lib/python3.10/site-packages/hdmf/utils.py:668: UserWarning: Ignoring cached namespace 'core' version 2.2.2 because version 2.6.0-alpha is already loaded.\n",
      "  return func(args[0], **pargs)\n",
      "WARNING:root:downloading a 2571.776MiB file from http://api.brain-map.org//api/v2/well_known_file_download/1026124326\n",
      "Downloading: 100%|████████████████████████████████████████████████████████| 2.70G/2.70G [00:23<00:00, 116MB/s]\n",
      "/local1/.local/miniconda-23.10.0/envs/bmtk-py3.10/lib/python3.10/site-packages/hdmf/utils.py:668: UserWarning: Ignoring cached namespace 'hdmf-common' version 1.1.3 because version 1.8.0 is already loaded.\n",
      "  return func(args[0], **pargs)\n",
      "/local1/.local/miniconda-23.10.0/envs/bmtk-py3.10/lib/python3.10/site-packages/hdmf/utils.py:668: UserWarning: Ignoring cached namespace 'core' version 2.2.2 because version 2.6.0-alpha is already loaded.\n",
      "  return func(args[0], **pargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<allensdk.brain_observatory.ecephys.ecephys_session.EcephysSession at 0x7f2563ee0eb0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from allensdk.brain_observatory.ecephys.ecephys_project_cache import EcephysProjectCache\n",
    "\n",
    "cache = EcephysProjectCache.from_warehouse(\n",
    "    manifest='./ecephys_cache_dir/neuropixels.manifest.json'\n",
    ")\n",
    "cache.get_session_data(715093703)\n",
    "cache.get_session_data(798911424)\n",
    "cache.get_session_data(754829445)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc957f1-abf5-4f0e-8304-89f207db88e4",
   "metadata": {},
   "source": [
    "By defaul the NWB files will be downloaded into the *ecephys_cache_dir*. Since nwb files are essentially just structured HDF5 files you can use tools like [HDFView](https://www.hdfgroup.org/downloads/hdfview/) or [h5py](https://www.h5py.org/) to read them once they have been downloaded. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f99daefa-2859-491c-8226-2edc181e8afd",
   "metadata": {},
   "source": [
    "### Step 2: Connecting VISL and Hippocampal onto our V1 cells."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba9ede7-b667-4038-ba9a-3f46076e8a1e",
   "metadata": {},
   "source": [
    "To simulation synaptic stimulation from the VisL and Hippocampal cell recordings onto our V1 model, we will need to create a population of virtual cells representing the new cells and synapses. Unforantely the electrophyiology data doesn't include information about network geometry so it is up to the modeler to decide how to connection the experimental data into our network.\n",
    "\n",
    "As we did before we will separate node populations called 'VISl' and 'Hippocampus' and use the NetworkBuilder to create feedforward synaptic connections\n",
    "\n",
    "```python\n",
    "visl = NetworkBuilder('VISl')\n",
    "visl.add_nodes(\n",
    "    N=n_visl_units,\n",
    "    model_type='virtual',\n",
    "    ...\n",
    ")\n",
    "visl.add_edges(\n",
    "    source=visal.nodes(),\n",
    "    target=visp.nodes(ei='e'), \n",
    "    connection_rule=connection_rule_e2e,\n",
    "    dynamics_params='AMPA_ExcToExc.json',\n",
    "    model_template='Exp2Syn',\n",
    "    ...\n",
    ")\n",
    "\n",
    "```\n",
    "\n",
    "See the *./build_network.nwb_inputs.py* for the full script that builds the SONATA network found in *./network_nwb_inputs/*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d7297f-d370-44c4-aa80-eb111367c040",
   "metadata": {},
   "source": [
    "### Step 3: Updating the configuration file to include NWB data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3598b866-32db-4f70-974d-fe7d59abe2e7",
   "metadata": {},
   "source": [
    "Before we can run the simulation we must update the SONATA configuration file so that the simulation:\n",
    "1. Knows which .nwb files to fetch spiking data from\n",
    "2. Knows how to map cells (eg. NWB units) from our experimental data to cells (eg. SONATA nodes) in our 'VISl' and 'hippocampus' populations.\n",
    "3. Know which interval of the experimental data to use in our simulation.\n",
    "\n",
    "The most straight forward way of doing this is to add the following to our configuration file (*config.nwb_inputs.json*) in the \"inputs\" section:\n",
    "\n",
    "```json\n",
    "\"inputs\": {\n",
    "    \"hippo_spikes\": {\n",
    "        \"input_type\": \"spikes\",\n",
    "        \"module\": \"ecephys_probe\",\n",
    "        \"node_set\": \"hippocampus\",\n",
    "        \"input_file\": \"./ecephys_cache_dir/session_715093703/session_715093703.nwb\",\n",
    "        \"units\": {\n",
    "            \"location\": [\"CA1\", \"CA3\", \"Po\"]\n",
    "        }\n",
    "        \"mapping\": \"sample\",\n",
    "        \"interval\": {\n",
    "            \"interval_name\": \"drifting_gratings\",\n",
    "            \"temporal_frequency\": 4.0,\n",
    "            \"orientation\": 90\n",
    "        }\n",
    "\n",
    "    },\n",
    "    \"visl_spikes\": {\n",
    "        \"input_type\": \"spikes\",\n",
    "        \"module\": \"ecephys_probe\",\n",
    "        \"node_set\": \"VISl\",\n",
    "        \"input_file\": \"./ecephys_cache_dir/session_715093703/session_715093703.nwb\",\n",
    "        \"mapping\": \"sample\",\n",
    "        \"units\": {\n",
    "            \"location\": \"VISl\",\n",
    "        }\n",
    "        \"interval\": {\n",
    "            \"interval_name\": \"drifting_gratings\",\n",
    "            \"temporal_frequency\": 4.0,\n",
    "            \"orientation\": 90\n",
    "        },\n",
    "    }\n",
    "}\n",
    "```\n",
    "* The **input_type** and **module** will always be set to values `spikes` and `ecephys_probe`, respectively, when importing extracellular electrophysiology NWB files into your simulation.\n",
    "* The **node_set** is the subset of cells in our network to use as virtual cells that are generating spikes.\n",
    "* The **input_file** in the name of the nwb file(s) to use for spikes. To use data from multiple sessions just use a list of files:\n",
    "```json\n",
    "    \"input_file\": [\n",
    "        \"./ecephys_cache_dir/session_715093703/session_715093703.nwb\",\n",
    "        \"./ecephys_cache_dir/session_798911424/session_798911424.nwb\",\n",
    "        \"./ecephys_cache_dir/session_754829445/session_754829445.nwb\"\n",
    "    ]\n",
    "```\n",
    "* The **units** field tell us which units from the nwb file to take their spiking data from based on either specifc keywords and/or unit-id. In the Neuropixels NWB files each unit has an field called \"location\" to determine which region the data came from, which we can use here to tell that for our model's \"hippocampus\" cells use any data coming from either the CA1, CA3 or Po regions.\n",
    "* **mapping** tells how to map NWB **units** -> SONATA **node_set**. Setting the value to `sample` to do a random mapping without replacement. You can also use options `sample_with_replacment`, useful if you have more nodes in your model than units in your data. Or if you have a specific mapping from NWB unit_ids to SONATA node_ids you can use optionn `units_map` (in which case **units** will point to a csv file).\n",
    "* **interval** tells simulation which interval of time to fetch spikes from. Inside the NWB file there is a stimulus table that marks the stimuli at any given epoch of time. We use this table to only get spikes recorded which a \"drifting grating\" stimuli was present with a given orientation and frequency. If you know the specific time you can also use option\n",
    "```json\n",
    "    \"interval\": [start_time_ms, end_time_ms]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef2aadb1-2d31-4d26-8574-591229cd570c",
   "metadata": {},
   "source": [
    "And finally we are ready to run our simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f77bfceb-64f0-4cd1-91a8-83aac4acfc83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-03 15:07:39,747 [INFO] Created log file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:NEURONIOUtils:Created log file\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-03 15:07:39,870 [INFO] Building cells.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:NEURONIOUtils:Building cells.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-03 15:07:49,864 [INFO] Building recurrent connections\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:NEURONIOUtils:Building recurrent connections\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-03 15:07:49,907 [INFO] Building virtual cell stimulations for LGN_spikes_sonata\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:NEURONIOUtils:Building virtual cell stimulations for LGN_spikes_sonata\n",
      "/local1/.local/miniconda-23.10.0/envs/bmtk-py3.10/lib/python3.10/site-packages/hdmf/utils.py:668: UserWarning: Ignoring cached namespace 'hdmf-common' version 1.1.3 because version 1.8.0 is already loaded.\n",
      "  return func(args[0], **pargs)\n",
      "/local1/.local/miniconda-23.10.0/envs/bmtk-py3.10/lib/python3.10/site-packages/hdmf/utils.py:668: UserWarning: Ignoring cached namespace 'core' version 2.2.2 because version 2.6.0-alpha is already loaded.\n",
      "  return func(args[0], **pargs)\n",
      "/local1/.local/miniconda-23.10.0/envs/bmtk-py3.10/lib/python3.10/site-packages/hdmf/utils.py:668: UserWarning: Ignoring cached namespace 'hdmf-common' version 1.1.3 because version 1.8.0 is already loaded.\n",
      "  return func(args[0], **pargs)\n",
      "/local1/.local/miniconda-23.10.0/envs/bmtk-py3.10/lib/python3.10/site-packages/hdmf/utils.py:668: UserWarning: Ignoring cached namespace 'core' version 2.2.2 because version 2.6.0-alpha is already loaded.\n",
      "  return func(args[0], **pargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-03 15:07:56,422 [INFO] Building virtual cell stimulations for VISl_spikes_nwb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:NEURONIOUtils:Building virtual cell stimulations for VISl_spikes_nwb\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-03 15:08:00,126 [INFO] Building virtual cell stimulations for Hipp_spikes_nwb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:NEURONIOUtils:Building virtual cell stimulations for Hipp_spikes_nwb\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-03 15:08:02,831 [INFO] Running simulation for 2000.000 ms with the time step 0.100 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:NEURONIOUtils:Running simulation for 2000.000 ms with the time step 0.100 ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-03 15:08:02,833 [INFO] Starting timestep: 0 at t_sim: 0.000 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:NEURONIOUtils:Starting timestep: 0 at t_sim: 0.000 ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-03 15:08:02,834 [INFO] Block save every 5000 steps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:NEURONIOUtils:Block save every 5000 steps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-03 15:09:01,211 [INFO]     step:5000 t_sim:500.00 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:NEURONIOUtils:    step:5000 t_sim:500.00 ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-03 15:09:57,522 [INFO]     step:10000 t_sim:1000.00 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:NEURONIOUtils:    step:10000 t_sim:1000.00 ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-03 15:11:00,912 [INFO]     step:15000 t_sim:1500.00 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:NEURONIOUtils:    step:15000 t_sim:1500.00 ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-03 15:12:04,649 [INFO]     step:20000 t_sim:2000.00 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:NEURONIOUtils:    step:20000 t_sim:2000.00 ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-05-03 15:12:04,700 [INFO] Simulation completed in 4.0 minutes, 1.87 seconds \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:NEURONIOUtils:Simulation completed in 4.0 minutes, 1.87 seconds \n"
     ]
    }
   ],
   "source": [
    "from bmtk.simulator import bionet\n",
    "\n",
    "bionet.reset()\n",
    "conf = bionet.Config.from_json('config.nwb_inputs.json')\n",
    "conf.build_env()\n",
    "\n",
    "net = bionet.BioNetwork.from_config(conf)\n",
    "sim = bionet.BioSimulator.from_config(conf, network=net)\n",
    "sim.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c64971d-41b2-4cab-afd2-a309f04863bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10f2d12-3f9e-46d0-a654-d2c2b0bb190e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Example: Dynamically generate custom spikes inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664cd168-a72c-4433-b1f3-cec9ec72399a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "448dfd35-f226-471c-98e5-929d5bc71571",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Example: Forcing spotonaneous synaptic activity within a network."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b18e4ca-aba8-4f41-ab52-8e19bfebf6c4",
   "metadata": {},
   "source": [
    "So far in this tutorials we've focused on generating stimuli using synaptic stimuli coming from outside our main modeled network. In other tutorials we should different types in input to drive a simulation including current-clamps, voltage-clamps, and extracellar stimulation. While these can be generate both the kinds of stimuli we might see in the experiments and living brains, they tend to not be very grainular, especially when we want to study the secondary effects of activity within a network.\n",
    "\n",
    "One option that BMTK gives use for having more grainular control of internal network activity is by forcing certain synapses to spontaneously fire at pre-determined times. Not only can this give us more control of network dynamics that would be much harder to achive using current clamps or feedforward spike trains. But it also let's us isolate external activity from recurrent activity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "463087a0-380e-459a-9abb-d70d659e94b2",
   "metadata": {},
   "source": [
    "In BMTK this is done by adding a new input type to the \"inputs\" section the SONATA config with **input_type** and **module** called `syn_activity`. And the minimum we must define the pre-synaptic cells that will spontaneously fire and a list of firing times:\n",
    "\n",
    "```json\n",
    "\"syn_activity\": {\n",
    "  \"input_type\": \"syn_activity\",\n",
    "  \"module\": \"syn_activity\",\n",
    "  \"precell_filter\": {\n",
    "      \"population\": \"VISp\",\n",
    "      \"ei\": \"e\"\n",
    "  },\n",
    "  \"timestamps\": [500.0, 1000.0, 1500.0, 2000.0, 2500.0, 3000.0, 3500.0]\n",
    "}\n",
    "```\n",
    "* **precell_filter** determines the synapses to sponataneously activate based on the presynaptic/source cell. In this case we tell BMTK sponataneous activity to apply on to synapses with a source-cell that has attributes `population==VISp` and `ei==e`. If you know exactly which cells you want to use you can filter by `node_id`:\n",
    "```json\n",
    "    \"node_id\": [0, 1, 2, 3],\n",
    "```\n",
    "* **timestamps** is a list of timestamps, in milliseconds, to activate the neuron following startup. If you have too many timestamps to add to the json directly, you can also pass in a string path to a txt file where each line is a timestamp.\n",
    "\n",
    "\n",
    "In the above example, all the synapses with VISp, exc pre-synaptic connections will fire at the given timestamp. For further grainular control you can all set the **postcell_filter** too for filtering out synapses based on post-synaptic cell. For example if you want spontaneous firing in exc -> inh connections (the above example would also include exc -> exc synapses:\n",
    "\n",
    "```json\n",
    "\"syn_activity\": {\n",
    "  \"input_type\": \"syn_activity\",\n",
    "  \"module\": \"syn_activity\",\n",
    "  \"precell_filter\": {\n",
    "      \"population\": \"VISp\",\n",
    "      \"ei\": \"e\"\n",
    "  },\n",
    "  \"postcell_filter\": {\n",
    "      \"population\": \"VISp\",\n",
    "      \"ei\": \"i\"\n",
    "  },\n",
    "  \"timestamps\": [500.0, 1000.0, 1500.0, 2000.0, 2500.0, 3000.0, 3500.0]\n",
    "}\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957112fc-f8ae-4841-95dd-0a0bd81be884",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bmtk.simulator import bionet\n",
    "\n",
    "bionet.reset()\n",
    "conf = bionet.Config.from_json('config.spont_syns.json')\n",
    "conf.build_env()\n",
    "\n",
    "net = bionet.BioNetwork.from_config(conf)\n",
    "sim = bionet.BioSimulator.from_config(conf, network=net)\n",
    "sim.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efdd66b3-53a0-479b-bbc4-af03a704028a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a31a3b58-880b-42f5-bb0a-39e261610aa1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Replaying recurrent activity from previous simulations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5644c4b2-3b7b-4ebb-857e-49a21061e32d",
   "metadata": {},
   "source": [
    "**TODO** Do I want to include this here or in another tutorial of its own?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b61a12e-a44c-4c67-b075-f663b599d449",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bmtk-py3.10",
   "language": "python",
   "name": "bmtk-py3.10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
